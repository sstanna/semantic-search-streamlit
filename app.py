import streamlit as st
import pandas as pd
from sentence_transformers import SentenceTransformer, util
import os
import glob

# Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð¼Ð¾Ð´ÐµÐ»ÑŒ
@st.cache_resource
def load_model():
    return SentenceTransformer('all-MiniLM-L6-v2')

model = load_model()

# Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð¸ Ð¾Ð±ÑŠÐµÐ´Ð¸Ð½ÑÐµÐ¼ Ð²ÑÐµ CSV Ð¸Ð· ÑƒÐºÐ°Ð·Ð°Ð½Ð½Ð¾Ð¹ Ð¿Ð°Ð¿ÐºÐ¸
@st.cache_data
def load_data():
    folder_path = "C:/skilfactory/data"
    all_files = glob.glob(os.path.join(folder_path, "*.csv"))
    dfs = []
    for file in all_files:
        df = pd.read_csv(file)
        df["source_file"] = os.path.basename(file)
        dfs.append(df)
    full_df = pd.concat(dfs, ignore_index=True)
    return full_df

# Ð˜Ð½Ñ‚ÐµÑ€Ñ„ÐµÐ¹Ñ Streamlit
st.title("ðŸ” Ð¡ÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð¿Ð¾Ð¸ÑÐº Ð¿Ð¾ ÑÐ¾Ñ†ÑÐµÑ‚ÑÐ¼")

# Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ
data = load_data()
st.write(f"Ð—Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð¾ Ð¿Ð¾ÑÑ‚Ð¾Ð²: {len(data)}")

# Ð’Ð²Ð¾Ð´ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°
query = st.text_input("Ð’Ð²ÐµÐ´Ð¸Ñ‚Ðµ Ð¿Ð¾Ð¸ÑÐºÐ¾Ð²ÑƒÑŽ Ñ„Ñ€Ð°Ð·Ñƒ:")

if st.button("ðŸ”Ž ÐÐ°Ð¹Ñ‚Ð¸") and query:
    with st.spinner("ðŸ”„ Ð¡Ñ‡Ð¸Ñ‚Ð°ÐµÐ¼ ÑÐ¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³Ð¸, Ð¿Ð¾Ð´Ð¾Ð¶Ð´Ð¸Ñ‚Ðµ..."):
        # Ð¡Ð¾Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ð²ÑÐµ Ñ‚ÐµÐºÑÑ‚Ñ‹ Ð¸Ð· ÐºÐ¾Ð»Ð¾Ð½Ð¾Ðº
        text_entries = []
        meta = []

        for idx, row in data.iterrows():
            for col in ['doc_text', 'image2text', 'speech2text']:
                text = str(row[col]) if pd.notnull(row[col]) else ""
                if text.strip():
                    text_entries.append(text.strip())
                    meta.append({
                        "source_file": row["source_file"],
                        "column": col,
                        "text": text.strip()
                    })

        if not text_entries:
            st.warning("â— ÐÐµÑ‚ Ñ‚ÐµÐºÑÑ‚Ð¾Ð² Ð´Ð»Ñ Ð¿Ð¾Ð¸ÑÐºÐ°. ÐŸÑ€Ð¾Ð²ÐµÑ€ÑŒ ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ð¼Ð¾Ðµ Ñ„Ð°Ð¹Ð»Ð¾Ð².")
        else:
            # Ð­Ð¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³Ð¸
            query_embedding = model.encode(query, convert_to_tensor=True)
            corpus_embeddings = model.encode(text_entries, convert_to_tensor=True)

            # Ð¡Ñ‡Ð¸Ñ‚Ð°ÐµÐ¼ ÑÑ…Ð¾Ð´ÑÑ‚Ð²Ð¾
            similarities = util.cos_sim(query_embedding, corpus_embeddings)[0]

            # Ð¢Ð¾Ð¿-N Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²
            top_n = min(10, len(similarities))
            top_results = similarities.argsort(descending=True)[:top_n]

            st.subheader("ðŸ” Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð¿Ð¾Ð¸ÑÐºÐ°:")
            for idx in top_results:
                score = similarities[idx].item()
                result = meta[idx]
                st.markdown(f"""
                **Ð˜ÑÑ‚Ð¾Ñ‡Ð½Ð¸Ðº**: `{result['source_file']}`  
                **Ð¢Ð¸Ð¿ Ñ‚ÐµÐºÑÑ‚Ð°**: `{result['column']}`  
                **Ð¡Ñ…Ð¾Ð´ÑÑ‚Ð²Ð¾**: `{score:.4f}`  
                > {result['text']}
                ---
                """)


    # Ð­Ð¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³Ð¸
    query_embedding = model.encode(query, convert_to_tensor=True)
    corpus_embeddings = model.encode(text_entries, convert_to_tensor=True)

    # Ð¡Ñ‡Ð¸Ñ‚Ð°ÐµÐ¼ ÑÑ…Ð¾Ð´ÑÑ‚Ð²Ð¾
    similarities = util.cos_sim(query_embedding, corpus_embeddings)[0]

    # Ð¢Ð¾Ð¿-N Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²
    top_n = min(10, len(similarities))
    top_results = similarities.argsort(descending=True)[:top_n]

    st.subheader("ðŸ” Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð¿Ð¾Ð¸ÑÐºÐ°:")
    for idx in top_results:
        score = similarities[idx].item()
        result = meta[idx]
        st.markdown(f"""
        **Ð˜ÑÑ‚Ð¾Ñ‡Ð½Ð¸Ðº**: `{result['source_file']}`  
        **Ð¢Ð¸Ð¿ Ñ‚ÐµÐºÑÑ‚Ð°**: `{result['column']}`  
        **Ð¡Ñ…Ð¾Ð´ÑÑ‚Ð²Ð¾**: `{score:.4f}`  
        > {result['text']}
        ---
        """)
